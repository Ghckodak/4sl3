{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X, t = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size = 1/5, random_state = 25) #split the set\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDes(alpha,X_train_2class,t_tr,iterations):\n",
    "    w = np.ones(31)\n",
    "    m = len(X_train_2class)\n",
    "    z = np.zeros(m)\n",
    "    y = np.zeros(m)\n",
    "    n = len(t_tr)\n",
    "    newcol = np.ones(m)\n",
    "    X_tr = np.insert(X_train_2class,0,newcol,axis=1)\n",
    "\n",
    "    cost = np.zeros(iterations)\n",
    "    for i in range (iterations):\n",
    "        z = np.dot(X_tr,w)\n",
    "        y = 1/(1+np.exp(-z))\n",
    "        diff = y - t_tr\n",
    "        grad = np.dot(X_tr.T,diff)\n",
    "        grad = grad/m\n",
    "        w = w - alpha*grad\n",
    "        for j in range(m):\n",
    "            cost[i] = cost[i] + (t_tr[j]*np.logaddexp(0,-z[j]) + (1-t_tr[j])*np.logaddexp(0,z[j]))\n",
    "        cost[i] = cost[i]/m\n",
    "    return w,cost,z,y\n",
    "\n",
    "\n",
    "def PR(y1,t_tr):\n",
    "    TN = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range (len(y1)):\n",
    "        if (y1[i] == 0 and t_tr[i] == 0):\n",
    "            TN+=1\n",
    "        if (y1[i] == 1 and t_tr[i] == 1):\n",
    "            TP+=1\n",
    "        if (y1[i] == 0 and t_tr[i] == 1):\n",
    "            FN+=1\n",
    "        if (y1[i] == 1 and t_tr[i] == 0):\n",
    "            FP+=1\n",
    "    \n",
    "    miss_classification_rate = (FN+FP)/(TN+TP+FN+FP)\n",
    "    precise = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1_score = 2*precise*recall/(precise+recall)\n",
    "    return precise,recall,miss_classification_rate,F1_score\n",
    "#comput PR Curve\n",
    "def plotPR(z_test):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    p_matrix = np.zeros(len(z_test))\n",
    "    r_matrix = np.zeros(len(z_test))\n",
    "    y_pr = np.zeros(len(z_test))\n",
    "    for i in range(len(z_test)):\n",
    "        for j in range (len(z_test)):\n",
    "            if(z_test[i]>=z_test[j]):\n",
    "                y_pr[j] = 1\n",
    "        for k in range (len(z_test)):\n",
    "            if (y_pr[k] == 0 and t_test_2class[k] == 0):\n",
    "                TN+=1\n",
    "            if (y_pr[k] == 1 and t_test_2class[k] == 1):\n",
    "                TP+=1\n",
    "            if (y_pr[k] ==1 and t_test_2class[k] == 0):\n",
    "                FP +=1\n",
    "            if (y_pr[k] == 0 and t_test_2class[k] == 1):\n",
    "                FN+=1\n",
    "        p = (TP)/(TP+FP)\n",
    "        r = (TP)/(TP+FN)\n",
    "        p_matrix[i] = p\n",
    "        r_matrix[i] = r\n",
    "    return p_matrix,r_matrix\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,cost,z,y= gradientDes(0.5,X_train,t_train,1000)\n",
    "new_col = np.ones(len(X_test))\n",
    "X1_test_2class = np.insert(X_test,0,new_col,axis=1)\n",
    "z_test = np.dot(X1_test_2class,w)\n",
    "y_test = np.zeros(len(z_test))\n",
    "for i in range(len(z_test)):\n",
    "    if(z_test[i]>=0):\n",
    "        y_test[i] = 1\n",
    "\n",
    "precise,recall,miss_classification_rate,F1_score = PR(y_test,t_test)\n",
    "p_matrix,r_matrix = plotPR(z_test)\n",
    "p_matrix = np.min(p_matrix)+(p_matrix - np.min(p_matrix))/(np.max(p_matrix)-np.min(p_matrix))*(1-0.65)\n",
    "r_matrix = NormalizeData(r_matrix)\n",
    "#scikit learn\n",
    "clf = LogisticRegression(random_state=0,solver='liblinear',multi_class='auto').fit(X_train, t_train)\n",
    "predictionLR = clf.predict(X_test_2class)\n",
    "precision, recall, thresholds = precision_recall_curve(t_test, predictionLR)\n",
    "plt.plot(r_matrix,p_matrix,color='b',label='mine')\n",
    "plt.plot(recall,precision,color='g',label='sklearn')\n",
    "plt.title(\"PR curve for two LR models\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "def sort(X_train,X_test):\n",
    "    M = len(X_test)\n",
    "    N = len(X_train)\n",
    "    dist = np.zeros((M,N))\n",
    "    for i in range (len(X_test)):\n",
    "        for j in range (len(X_train)):\n",
    "            diff = X_test[i] - X_train[j]\n",
    "            dist[i,j] = np.dot(diff,diff)\n",
    "    index = np.argsort(dist,axis = 1)\n",
    "    return index\n",
    "\n",
    "def kNN(K,index,X_test,t_train,t_test):\n",
    "    \n",
    "    result = np.zeros((len(X_test)))\n",
    "    for i in range (len(X_test)):\n",
    "        count0 = 0\n",
    "        count1 = 0\n",
    "        for j in range (K):\n",
    "            if (t_train[index[i,j]] == 0):\n",
    "                count0+=1\n",
    "            else:\n",
    "                count1+=1\n",
    "        if(count0>=count1):\n",
    "            result[i] = 0\n",
    "        else:\n",
    "            result[i] = 1\n",
    "\n",
    "    error = kFold(5,result,t_test,0)\n",
    "\n",
    "    return result, error\n",
    "\n",
    "\n",
    "def getRMSE(X_train,X_valid,t_train,t_valid):\n",
    "    Xtr = getSet(X_train)    # add a column of one\n",
    "    A = np.dot(Xtr.T,Xtr)\n",
    "    A1 = np.linalg.inv(A) #the inverse of A\n",
    "    B = np.dot(Xtr.T,t_train)\n",
    "    w =np.dot(A1,B)\n",
    "    y = np.dot(Xtr,w)\n",
    "    \n",
    "    # prepare the validation set\n",
    "    Xva = getSet(X_valid)\n",
    "    y_valid = np.dot(Xva,w)\n",
    "    diff_valid = np.subtract(t_valid,y_valid)\n",
    "    err_valid = np.dot(diff_valid, diff_valid)/len(X_valid)\n",
    "    RMSE_valid = np.sqrt(err_valid)\n",
    "\n",
    "    return RMSE_valid\n",
    "\n",
    "\n",
    "def kFold(splits, X, t, arg):\n",
    "    res = 0\n",
    "    kf=KFold(n_splits=splits)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        t_train, t_test = t[train_index], t[test_index]\n",
    "\n",
    "        res = res + getRMSE(X_train,X_test,t_train,t_test)\n",
    "  \n",
    "    error = res/splits\n",
    "\n",
    "    return error    \n",
    "\n",
    "\n",
    "def getSet(X):\n",
    "    size=X.shape\n",
    "    Xtr=np.ones( (size[0],1) )\n",
    "    if (X.ndim == 1):\n",
    "        Xtr=np.column_stack((Xtr, X))\n",
    "    else: \n",
    "        for j in range(size[1]):\n",
    "            Xtr=np.column_stack((Xtr, X[:,j]))\n",
    "    return Xtr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = sort(X_train,X_test)\n",
    "\n",
    "output =[]\n",
    "k_error = []\n",
    "for k in range(5):\n",
    "    a, b = kNN(k+1,index,X_test,t_train,t_test)\n",
    "    output.append(b)\n",
    "\n",
    "a = 0\n",
    "\n",
    "for m in range(5):\n",
    "\n",
    "    knn_classifier=KNeighborsClassifier(m+1)\n",
    "    knn_classifier.fit(X_train,t_train)\n",
    "    y_predict=knn_classifier.predict(X_test)\n",
    "    scores=knn_classifier.score(X_test,t_test)\n",
    "    k_error.append(1-scores)\n",
    "\n",
    "K=5\n",
    "k_index = np.arange(K)+1\n",
    "\n",
    "plt.plot(k_index,k_error,color = 'green', label = 'sklearn')\n",
    "plt.plot(k_index, output, color = 'b', label = 'mine')\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.title(\"My/sklearn kFold implementation\")\n",
    "plt.legend()\n",
    "\n",
    "knn_classifier=KNeighborsClassifier(4)\n",
    "knn_classifier.fit(X_train,t_train)\n",
    "y_predict=knn_classifier.predict(X_test)\n",
    "\n",
    "a, b = kNN(4,index,X_test,t_train,t_test)\n",
    "precise,recall,miss_classification_rate,F1_score=PR(predictionLR,t_test_2class)\n",
    "\n",
    "print(miss_classification_rate,F1_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
