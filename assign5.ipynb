{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8262679  -1.54205887  0.96866858  0.57237498]\n",
      " [-0.5859893  -0.11357767  1.49099905  0.85091245]\n",
      " [-0.21690679 -0.23431156 -0.4007196   0.5154012 ]\n",
      " ...\n",
      " [ 1.10865039  0.18643168 -0.13995204  0.82053048]\n",
      " [-1.02129319 -0.41612509  0.08534552  0.33371887]\n",
      " [ 0.54620116 -0.0257496  -1.00242774  0.64707517]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_table('Data/data_banknote_authentication.txt', sep = \",\", header=None)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "t = dataset.iloc[:, -1].values\n",
    "\n",
    "# split the training set, validation set and test set of ratio 6:2:2\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2, random_state=8775)\n",
    "X_train, X_valid, t_train, t_valid = train_test_split(X_train, t_train, test_size=0.25, random_state=8775)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "X_valid = sc.transform(X_valid)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.65888615e-15]\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier( activation='relu', \n",
    "                    solver='sgd', \n",
    "                    learning_rate='constant', \n",
    "                    learning_rate_init=0.05,\n",
    "                    hidden_layer_sizes=(5, 2), \n",
    "                    n_iter_no_change=100,\n",
    "                    early_stopping=True)\n",
    "\n",
    "def NNClassifier(input, hidden_layer_sizes,epochs, learning_rate):\n",
    "    layer_1_size = hidden_layer_sizes[0]\n",
    "    layer_2_size = hidden_layer_sizes[1]\n",
    "\n",
    "    input = np.insert(input,0,1)     # add dummy one\n",
    "    w_1 = np.ones((layer_1_size, 5))\n",
    "    z_1 = np.dot(w_1, input.T)\n",
    "    h_1 = ReLU(z_1)\n",
    "\n",
    "    h_1 = np.insert(h_1,0,1)\n",
    "    w_2 = np.ones((layer_2_size, layer_1_size+1))\n",
    "    z_2 = np.dot(w_2, h_1.T)\n",
    "    h_2 = ReLU(z_2)\n",
    "\n",
    "    h_2 = np.insert(h_2,0,1)\n",
    "    w_3 = np.ones((1, layer_2_size+1))\n",
    "    z_3 = np.dot(w_3, h_2.T)\n",
    "    output = np.power((1 + np.exp(-z_3)), -1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def ReLU(matrix):\n",
    "    for element in matrix:\n",
    "        if (element<0):\n",
    "            element=0\n",
    "    return matrix\n",
    "\n",
    "inp=np.asarray([1,-2,-4,-5])\n",
    "o=NNClassifier(inp,hidden_layer_sizes=(2,2),epochs=0,learning_rate=0)\n",
    "\n",
    "print(o)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
